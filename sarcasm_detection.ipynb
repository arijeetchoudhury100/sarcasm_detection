{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarcasm_detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB9wJwoJEaTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnzV5v3fJtMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(path):\n",
        "  '''Function to load data.\n",
        "     Data is present in a json file\n",
        "     parameters: filename->path to the json file\n",
        "  '''  \n",
        "  data = []\n",
        "  labels = []\n",
        "  fp = open(path,'r')\n",
        "  for l in fp:\n",
        "    dict_ = json.loads(l)\n",
        "    data.append(dict_['headline'])\n",
        "    labels.append(dict_['is_sarcastic'])\n",
        "  return data,labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFQRhTKKKGFS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3be09bea-416f-4f28-9c5a-4ef6b5588710"
      },
      "source": [
        "#load the data\n",
        "data,labels = load_data('Sarcasm_Headlines_Dataset.json')\n",
        "print('Total no. of samples:',len(data))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no. of samples: 26709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbexubwJQ_BK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split into training and validation sets\n",
        "def split_data(split_factor,data,labels):\n",
        "  '''Function to split the data into training and testing sets\n",
        "     parameters:\n",
        "     split_factor-> fraction of data to be kept as trainin data\n",
        "     data-> list of news headlines\n",
        "     labels-> corresponding labels\n",
        "  '''\n",
        "  m = len(data) #size of the data\n",
        "  num_train = int(m*split_factor)\n",
        "  training_examples = data[0:num_train]\n",
        "  testing_examples = data[num_train:]\n",
        "  training_labels = labels[0:num_train]\n",
        "  testing_labels = labels[num_train:]\n",
        "  return training_examples,training_labels,testing_examples,testing_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzoOcbFrSKc7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "21e0e77e-972f-4b49-d60d-3b4ef35c852f"
      },
      "source": [
        "#split the data\n",
        "split_factor = 0.9\n",
        "train_x,train_y,test_x,test_y = split_data(split_factor,data,labels)\n",
        "print('no. of training examples=',len(train_x))\n",
        "print('no. of testing examples=',len(test_x))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no. of training examples= 24038\n",
            "no. of testing examples= 2671\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhcpmixIM9JB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import tokenizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDF5bOi7Nq6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenize and pad data\n",
        "vocab_size = 10000\n",
        "max_length = 150\n",
        "pad = 'post'\n",
        "trunc = 'pre'\n",
        "\n",
        "#generate indices for words(tokens)\n",
        "tokenizer = Tokenizer(num_words=vocab_size,oov_token=\"<unk>\")\n",
        "tokenizer.fit_on_texts(train_x)\n",
        "word_to_indices = tokenizer.word_index\n",
        "\n",
        "#convert sentences to sequence of tokens\n",
        "train_sequences = tokenizer.texts_to_sequences(train_x)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_x)\n",
        "\n",
        "#pad the sequences so that each sequence is of same length\n",
        "padded_train_sequences = pad_sequences(train_sequences,maxlen=max_length,padding = pad,truncating = trunc)\n",
        "padded_test_sequences = pad_sequences(test_sequences,maxlen=max_length,padding = pad,truncating = trunc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYlgUBXzWwbs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b368d50e-e642-42e1-a6ba-9bbcdcc276eb"
      },
      "source": [
        "print(padded_train_sequences.shape)\n",
        "print(padded_test_sequences.shape)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24038, 150)\n",
            "(2671, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueLexu1AXWw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}